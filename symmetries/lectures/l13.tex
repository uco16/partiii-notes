% lecture notes by Umut Ã–zer
% course: symmetries
\lhead{Lecture 13: November 09}
\section{Two particle states}%
\label{sec:two_particle_states}

Let us start with some motivation.
Assume we have two particles, each occupying a two-particle Hilbert space $\mathcal{H}_i = \left\{ \ket{\uparrow}_i, \ket{\downarrow}_i \right\}$, $i = 1, 2$.
The two particle states are states like $\ket{\uparrow}_1 \ket{\downarrow}_2$ or $\ket{\uparrow}_1 \ket{\downarrow}_2 - \ket{\downarrow}_1 \ket{\uparrow}_2 \in \mathcal{H}_{12}$.
To analyse this we will have to think more about how to combine two representations.

\section{Tensor product}%
\label{sec:tensor_product}

\begin{definition}[]
  Let $R_1$ and $R_2$ be two representations of $\mathfrak{g}$ on representations spaces $V_1$ and $V_2$ of dimension $d_1$ and $d_2$ respectively.
  We can define the \emph{direct sum} $R_1 \oplus R_2$ to be the new representation acting on $X \in V_1 \oplus V_2$ as
  \begin{equation}
    (R_1 \oplus R_2)(X) = 
    \begin{pmatrix}
      R_1(X) & 0 \\
      0 & R_2(X) \\
    \end{pmatrix}
  \end{equation}
\end{definition}

\begin{definition}[]
  Given two vector spaces $V_1$ and $V_2$, we define the \emph{(tensor) product space}
  \begin{equation}
    V_1 \otimes V_2 = \text{Span}_F \left\{ v_1 \otimes v_2 \mid v_1 \in V_1, v_2 \in V_2 \right\}
  \end{equation}
  where the tensor product satisfies $\forall v_i \in V_i, \alpha \in F$:
  \begin{itemize}
    \item $(v_1 + w_1) \otimes (v_2 + w_2) = v_1 \otimes v_2 + w_1 \otimes v_2 + v_1 \otimes w_2 + w_1 \otimes w_2$
    \item $\alpha(v_1 \otimes v_2) = (\alpha v_1) \otimes v_2 = v_1 \otimes (\alpha v_2)$
  \end{itemize}
\end{definition}

\begin{definition}[]
  Given two linear maps $M_i \colon V_i \to V_i$, $i = 1, 2$, we define the \emph{tensor product map}
  \begin{equation}
    \begin{split}
      (M_1 \otimes M_2) \colon V_1 \otimes V_2 \ &\to\  V_1 \otimes V_2 \\
      v_1 \otimes v_2 \ &\mapsto\  (M_1 v_1) \otimes (M_2 v_2).
    \end{split}
  \end{equation}
  We extend this action on the basis $v_1 \otimes v_2$ by linearity to the full tensor product space $V_1 \otimes V_2$.
\end{definition}

\begin{definition}[]
  Given representations $R_i$, $i = 1, 2$ of $\mathfrak{g}$ with corresponding representation spaces $V_i$, we have, for each element $X$ in the Lie algebra $\mathfrak{g}$, a map $R_i(X) \colon V_i \to V_i$.
  We now define the \emph{tensor product representation} $R_1 \otimes R_2$ with representation space $V_1 \otimes V_2$ which acts on all $X \in \mathfrak{g}$ as
  \begin{equation}
    \boxed{(R_1 \otimes R_2)(X) = R_1(X) \otimes I_2 + I_1 \otimes R_2(X)}
  \end{equation}
\end{definition}
\begin{leftbar}
  \begin{remark}
    Note that his is not the same as $R_1(X) \otimes R_2(X)$.
  \end{remark}
\end{leftbar}
Let us choose a particular set of basis vectors for the two vector spaces:
\begin{equation}
  B_1 = \left\{ V_1^j \mid j = 1, \dots , d_1 \right\} \qquad B_2 = \left\{ V_2^\alpha \mid \alpha = 1 ,\dots, d_2 \right\}.
\end{equation}
We can then represent $R_1 \otimes R_2$ as a `matrix' with $i, j = 1 , \dots, d_1$ and $\alpha, \beta = 1, \dots, d_2$ as
\begin{equation}
  (R_1 \otimes R_2)(X) = R_1(X)_{ij} \mathbb{1}_{ij} + \mathbb{1}_{ij} R_2(X)_{\alpha\beta}.
\end{equation}
The representation $R_1 \times R_2$ has dimension $d_1 \times d_2$.

\begin{exercise}
  Check that $R_1 \otimes R_2$ as defined is a representation of $\mathfrak{g}$.
\end{exercise}

\begin{leftbar}
  \begin{remark}
    In physics terms, the motivation for this construction come from the laws of quantum mechanics: multi-particle states live in the tensor product space of the individual one-particle states.
    The definition of the addition of angular momentum is described by this definition of the tensor product representation.
  \end{remark}
\end{leftbar}
\begin{leftbar}
  \begin{remark}
    Up to isomorphism, the tensor product is associative: $(R_1 \otimes R_2) \otimes R_2 = R_1 \otimes (R_2 \otimes R_3)$.
  \end{remark}
\end{leftbar}

\section{Reducibility}%
\label{sec:reducibility}

\begin{definition}[]
  Let us recall that a representation $R$ with representation space $V$ has an \emph{invariant subspace} $U \subset V$ if $R(X) u \in U$ for all $X \in \mathfrak{g}$ and all $u \in U$.
\end{definition}
We already know that an \emph{irreducible} representation (irrep) has no non-trivial invariant subspace.
\begin{definition}[]
  A \emph{fully reducible} representation can be expressed as a direct sum of irreps.
\end{definition}
Let us look at what this means for a particular basis.
If $R$ has a non-trivial invariant subspace, then we can find a basis that makes this manifest. In other words, we can find a basis such that $R(X)$ has block diagonal form:
\begin{equation}
  R(X) = 
  \begin{pmatrix}
    A(X) & B(X) \\
    0 & C(X) \\
  \end{pmatrix}.
\end{equation}
In this case, elements of $U$ correspond to vectors \(\begin{pmatrix}
u \\
0 \\
\end{pmatrix}\) for all elements $X$ of the Lie algebra $\mathfrak{g}$.

If $R$ is fully reducible, then $R = R_1 \oplus R_2 \oplus \dots \oplus R_l$.
Hence, we have a basis, where $R(X)$ is block diagonal, where the blocks are the individual irreps
\begin{equation}
  R(X) = 
  \begin{pmatrix}
    R_1(X) &  &  &  \\
	   & R_2(X) &  &  \\
    &  & \ddots &  \\
    &  &  & R_l(X) \\
  \end{pmatrix}.
\end{equation}

This is useful for us due to the following theorem, which we will not prove in this course:
\begin{theorem}[]
  Let $R_i$, $i = 1, \dots, m$, be finite-dimensional irreps of a simple Lie algebra $\mathfrak{g}$. The tensor product $(R_1 \otimes \dots \otimes R_m)$ is fully reducible.
  In other words,
  \begin{equation}
    R_1 \otimes R_2 \dots \otimes R_m \simeq \widetilde{R}_1 \oplus \widetilde{R}_2 \oplus \dots \oplus \widetilde{ R}_{m'}.
  \end{equation}
\end{theorem}
\begin{leftbar}
  \begin{remark}
    Another more mathematical way to say this is that the tensor representation forms a ring.
  \end{remark}
\end{leftbar}

\section{Tensor product of \texorpdfstring{$\mathfrak{su}(2)$}{the Lie algebra of SU(2)} representations}%
\label{sec:tensor_product_of_su2_reps}

Let $R_\Lambda$ and $R_{\Lambda'}$ be irreps of $\mathfrak{su}(2)$ with highest weights $\Lambda, \Lambda' \in \mathbb{N}_0$. Previously, we have found that $\dim(R_\Lambda) = \Lambda + 1$ and $\dim (R_{\Lambda'}) = \Lambda' + 1$.
Let $V_{\Lambda}$ and $V_{\Lambda'}$ be the respective representation spaces.
We then form the tensor product representation $R_{\Lambda} \otimes R_{\Lambda'}$ with the complex representation space $V_{\Lambda} \otimes V_{\Lambda'}$, by representing each $X \in \mathfrak{su}(2)$ by a matrix $(R_{\Lambda} \otimes R_{\Lambda'})(X)$ that acts as
\begin{equation}
  (R_{\Lambda} \otimes R_{\Lambda'})(X)(v \otimes v') = (R_{\Lambda}(X)v) \otimes v' + v \otimes (R_{\Lambda'}(X)v').
\end{equation}
We know that the dimension is simply the product of the two representation dimensions $\dim(R_{\Lambda} \otimes R_{\Lambda'}) = (\Lambda + 1)(\Lambda' + 1)$.
Moreover, we know that this has to be a fully reducible representation of $\mathfrak{su}(2)$, which means that we can write
\begin{equation}
  R_{\Lambda} \otimes R_{\Lambda'} = \bigoplus_{\Lambda'' \in \mathbb{N}_0} \mathcal{L}^{\Lambda''}_{\Lambda, \Lambda'} R_{\Lambda''}
\end{equation}
where the \emph{multiplicities} $\mathcal{L}^{\Lambda''}_{\Lambda, \Lambda'} \in \mathbb{N}_0$ are sometimes called \emph{Littlewood coefficents}.
\begin{leftbar}
  \begin{remark}
    In \emph{Foundations of Quantum Mechanics} and \emph{Group Theory}, we have met the Clebsch-Gordan coefficients.
    Clebsch-Gordan coefficients are matrix elements that are not always integers! So they are not the same as these multiplicities.
  \end{remark}
\end{leftbar}

Let us try to calculate these coefficients.
$V_\Lambda$ has a basis $\left\{ v^{\lambda} \right\}$ that are eigenvectors of $R_\Lambda(H)$ with eigenvalues $\lambda \in S_{\Lambda} = \left\{ -\Lambda, -\Lambda + 2, \dots, +\Lambda \right\}$. Similarly, we have the same for $V_{\Lambda'}$.
