% lecture notes by Umut Ã–zer
% course: gr
\lhead{Lecture 5: October 23}
\begin{example}[]
  A $(2,1)$ tensor acts on the one-forms $\omega, \eta \in \Lambda^1(\mathcal{M})$ on the manifold as
  \begin{equation}
    T(\omega, \eta; X) = T(\omega_\mu f^\mu, \eta_\mu f^\nu; X^\rho e_\rho) = \omega_\mu \eta_\nu X^\rho T \indices{^\mu ^\nu _\rho},
  \end{equation}
  where $X \in \mathfrak{X}(\mathcal{M})$. 
  Consider a coordinate transformation $\tilde e_\nu = A \indices{^\mu _\nu} e_\mu$ with $A \indices{^\mu _\nu} = \pdv{x^\mu}{ \tilde x^\nu}$ and $\tilde f^\rho = B \indices{ ^\rho _\sigma} f^\sigma$ with $B \indices{ ^\rho _\sigma} = \pdv{\tilde x ^\rho}{x^\sigma}$.
  Then a $(2, 1)$ tensor transforms as
  \begin{equation}
    \tilde T \indices{ ^\mu^\nu_\rho} = B \indices{^\mu_\sigma} B \indices{^\nu_\tau} A \indices{^\lambda_\rho} T \indices{^\sigma^\tau_\lambda}.
  \end{equation} 
  This is often taken as a definition of a tensor.
  What is really happening is that the tensor is a \emph{linear} map.
\end{example}

\subsection*{Motivation}%
\label{sub:motivation}

We care about tensors since we want the physical equations to be independent of the coordinates we are using.
To actually do calculations, we cannot use this abstract notation, but we really need to introduce coordinates.
However, we need to make sure that the results do not depend on coordinates, but are physically meaningful. This is why tensors are important for us.

\subsection{Tensor operations}%
\label{sub:tensor_operations}

There are a number of operations that we can perform on tensors:
\begin{itemize}
  \item vector space: can add / subtract or multiply by functions
  \item tensor product: if $S$ has rank $(p, q)$ and $T$ has rank $(r, s)$, then $S \otimes T$ has rank $(p + r, q + s)$ defined by
    \begin{multline}
      S \otimes T(\omega_1, \dots, \omega_p, \eta_1, \dots, \eta_r; X_1, \dots, X_q, Y_1, \dots Y_s) \\
      = S (\omega_1, \dots, \omega_p; X_1, \dots, X_q) T(\eta_1, \dots, \eta_r; Y_1, \dots, Y_s).
    \end{multline}
    In components, this is
    \begin{equation}
      (S \otimes T) \indices{^{\mu_1 \dots \mu_p \nu_1 \dots \nu_r}_{\rho_1 \dots \rho_s \sigma_1 \dots \sigma_s}} = S \indices{^{\eta_1 \dots \eta_p}_{\rho_1 \dots \rho_q}} T \indices{ ^{\nu_1 \dots \nu_r}_{\sigma_1 \dots \sigma_s}}.
    \end{equation}
  \item contraction: We can turn an $(r, s)$-tensor into an $(r-1, s-1)$-tensor. If $T$ is a $(2,1)$ tensor, then
    \begin{equation}
      S(\omega) = T(\omega, f^\mu; e_\mu)
    \end{equation}
    Since we sum over $\mu$, this is basis independent.
    In components, this is
    \begin{equation}
      S^\mu = T \indices{^\mu^\nu_\nu}.
    \end{equation}
    \begin{leftbar}
      \begin{remark}
	This is typically different from $(S')^\mu = T \indices{^\nu^\mu _\nu}$.
      \end{remark}
    \end{leftbar}
  \item (anti)-symmetrisation: For example, given a $(0,2)$-tensor $T$, we can define two new $(0, 2)$-tensors
    \begin{equation}
      S(X, Y) = \frac{1}{2} \left( T(X, Y) + T(Y, X) \right) \qquad
      A(X, Y) = \frac{1}{2} \left( T(X, Y) - T(Y, X) \right).
    \end{equation}
    In terms of components, we write
    \begin{equation}
      S_{\mu\nu} = \frac{1}{2} (T_{\mu\nu} + T_{\nu\mu}) \qquad
      A_{\mu\nu} = \frac{1}{2} (T_{\mu\nu} - T_{\nu\mu})
    \end{equation}
    \begin{leftbar}
      \begin{remark}
        This is similar to how we can decompose a matrix into its symmetric and anti-symmetric components.
      \end{remark}
    \end{leftbar}
    \begin{notation}[]
      We write 
      \begin{equation}
	T \indices{_{(\mu \nu)}} \coloneqq \frac{1}{2} (T_{\mu\nu} + T_{\nu \mu}) \qquad
	T \indices{_{[\mu \nu]}} \coloneqq \frac{1}{2} (T_{\mu\nu} - T_{\nu \mu}).
      \end{equation}
    \end{notation}
    We can also (anti)-symmetrise over multiple indices.
    \begin{example}[]
      \begin{align}
	T \indices{^\mu_{(\nu\rho\sigma)}} &= \frac{1}{3!} (T \indices{^\mu_{\nu\rho\sigma}} + 5 \text{ permutations}) \\
      T \indices{^\mu_{[\nu\rho\sigma]}} &= \frac{1}{3!} (T \indices{^\mu_{\nu\rho\sigma}} + \text{sign(perm)} \times \text{ permutations}) \\
      \end{align}
    \end{example}
    In general, we divide by $p!$, where $p$ is the number of indices we (anti)-symmetrise over.
  \item We can define a Lie derivative $\mathcal{L}_X$ on a tensor field.
\end{itemize}

The next part is $\varepsilon$ more interesting than all these preceding definitions. But the good thing is that $\varepsilon > 0$.

\subsection{Differential Forms}%
\label{sub:differential_forms}

\begin{definition}[p-forms]
  Totally anti-symmetric $(0, p)$-tensors are called \emph{$p$-forms}. The space of all $p$-forms is denoted $\Lambda^p (\mathcal{M})$.
\end{definition}
\begin{example}[]
  $0$-forms are simply functions.
\end{example}
In general, if the dimension of the manifold is $\dim M = n$, then $p$-forms have $\binom{n}{p}$ independent components.
$n$-forms are called \emph{top-forms}.
\begin{definition}[wedge product]
  Given $\omega \in \Lambda^p(\mathcal{M})$ and $\eta \in \Lambda^q (\mathcal{M})$, we can form a $(p + q)$-form by taking the tensor product and anti-symmetrising.
  This is the \emph{wedge product}
  \begin{equation}
    (\omega \wedge \eta)_{\mu_1 \dots \mu_p \nu_1 \dots \nu_q} = \frac{(p + q)!}{p! q!} \omega_{[\mu_1 \dots \mu_p} \eta_{\nu_1 \dots \nu_q]}
  \end{equation}
\end{definition}
\begin{example}[]
  For one-forms, we have $(\omega \wedge \eta)_{\mu\nu} = \omega_\mu \eta_\nu - \omega_\nu \eta_\mu$.
\end{example}
\begin{exercise}
  Show that in general $\omega \wedge \eta = (-1)^{pq} \eta \wedge \omega$.
\end{exercise}
Moreover, if you take the wedge product with a form by itself, you get $\omega \wedge \omega = $ for odd forms, but not necessarily for even forms.

\begin{example}[A wedge we have seen before]
  For $\mathcal{M} = \mathbb{R}^3$ and $\omega, \eta \in \Lambda^1(\mathcal{M})$, pick some coordinates $x_1, x_2, x_3$ and expand the one-form in the coordinate basis as
  \begin{align}
    (\omega \wedge \eta) &= (\omega_1 dx^1 + \omega_2 dx^2 + \omega_3 dx^3) \wedge (\eta_1 dx^1 + \eta_2 dx^2 + \eta_3 dx^3) \\
			 &= (\omega_1 \eta_2 - \eta_1 \omega_2) dx^1 \wedge dx^2
			 + (\omega_2 \eta_3 - \eta_2 \omega_3) dx^2 \wedge dx^3
			 + (\omega_3 \eta_1 - \eta_3 \omega_1) dx^3 \wedge dx^1 
  \end{align}
  These are the components of the \emph{cross-product} in $\mathbb{R}^3$!
  The cross-product is really a wedge product between forms.
  We thus find out that we really always got back a two-form by taking the cross-product between two one-forms. However, as we will see later, there is a natural correspondence between two-forms and one-forms.
\end{example}

In a coordinate basis, we write
\begin{equation}
  \omega = \frac{1}{p!} \omega_{\eta_1 \dots \mu_p} dx^{\mu_1} \wedge \dots \wedge dx^{\mu_p}.
\end{equation}

\section{The Exterior Derivative}%
\label{sec:the_exterior_derivative}

This is the second of three different derivatives we will meet, the first having been the Lie derivative.
Given a function $f$, we can construct a 1-form
\begin{equation}
  df = \pdv{f}{x^\mu} dx^\mu.
\end{equation}
In general, there is a map $d: \Lambda^p(\mathcal{M}) \to \Lambda^{p+1}(\mathcal{M})$. This is called the \emph{exterior derivative}.
\begin{leftbar}
  \begin{remark}
    The one that will be coming up is the \emph{covariant derivative}. With the Lie derivative and the covariant one, we get back an object that is the same as the one we feed in. Here, we get an object that is one dimension higher.
  \end{remark}
\end{leftbar}
There is also a (horrendous) coordinate-free definition, but it is easiest to work in coordinates, where
\begin{equation}
  d\omega = \frac{1}{p!} \pdv{\omega_{\mu_1 \dots \mu_p}}{x^\nu} dx^\nu \wedge dx^{\mu_1} \wedge \dots \wedge dx^{\mu_p}
\end{equation}
or
\begin{equation}
  (d\omega)_{\mu_1 \dots \mu_{p+1}} = (p+1) \partial_{[\mu_1} \omega_{\mu_2 \dots \mu_{p+1}]}.
\end{equation}
Again, we have seen this before in a different guise; we will see this later.
Because of anti-symmetry $d(d\omega) = 0$. We write this as $d^2 = 0$.
\begin{leftbar}
  \begin{remark}
    Whenever there is a second derivative, even with such a simple equation, there are beautiful things that follow. We will see this later.
  \end{remark}
\end{leftbar}
It is simple to show the following properties
\begin{itemize}
  \item $d(\omega \wedge\eta) = d\omega \wedge \eta + (-1)^p \omega \wedge d \omega$
  \item for pull-backs: $d(\varphi^* \omega) = \varphi^* d\omega$
  \item $\mathcal{L}_X (d\omega) = d(\mathcal{L}_X \omega)$
\end{itemize}
\begin{definition}[]
  A $p$-form is \emph{closed} if $d\omega =0$ everywhere.
\end{definition}
\begin{definition}[]
  A $p$-form is \emph{exact} if $\omega = d\eta$ everywhere for some $\eta$.
\end{definition}
\begin{corollary}
  The statement that $d^2 = 0$ implies that exact $p$-forms are automatically closed.
\end{corollary}

\begin{lemma}[Poincar\'e's Lemma]
  On $\mathbb{R}^n$, or locally on $\mathcal{M}$, 
  \begin{equation}
    \text{closed} \quad \implies \quad \text{exact}.
  \end{equation}
\end{lemma}
