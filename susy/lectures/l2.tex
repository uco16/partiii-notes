% lecture notes by Umut Ã–zer
% course: susy
\lhead{Lecture 2: January 21}

\begin{definition}[polynomials]
  We can define polynomials on a super vector space $\mathbb{R}^{p \mid q} = v$ as $O(V) \simeq \text{Sym}^*(V^*_0) \otimes \Lambda^* (V_1^*)$. They are of the form
  \begin{equation}
    c_{\underbrace{ijk \dots m}_{\mathclap{\text{symmetric}}} \underbrace{abc \dots d}_{\mathclap{\text{antisymmetric}}}} x^{i} x^{j} \dots x^{m} \psi^{a} \dots \psi^{d}.
  \end{equation}
\end{definition}
\begin{definition}[smooth functions]
  We define smooth functions on a super vector space to be $C^\infty(V) = C^\infty(V_0) \otimes \Lambda^* (V_1^*)$, so a generic function has an expansion
  \begin{equation}
    F(x^{i}, \psi^{a}) = f(x^{i}) * \rho_a (x^{i}) \psi^{a} + g_{ab} (x^{i}) \psi^{a} \psi^{b} + \dots + \frac{h(x)}{(\dim V_1)!} \epsilon_{ab \dots d} \psi^{a} \psi^{b} \dots \psi^{d},
  \end{equation}
  where the coefficients $f$, $\rho_{a}$, $g_{ab}$, \dots are smooth functions on $V_0$. We often call such functions $F(x^{i}, \psi^{a})$ \emph{superfields}, while the smooth functions $f, \rho_a, g_{ab}, \dots, h$ are the \emph{component fields}.
  Note that if $F(x, \psi)$ is bosonic, then the component fields with even indices $f, g_{ab}=-g_{ba}, \dots$ are bosonic whilst the ones with odd indices $\rho_a, \dots$ are fermionic.
\end{definition}
\begin{remark}
  This is reminiscent of a \emph{polyform} $F\in \Omega^*(V)$
  \begin{equation}
    F(x^{i}, dx^{i}) = f(x) + \rho_i(x) dx^{i} + g_{ij} (x) dx^{i} \wedge dx^{j} + \dots + h(x) dx^{i} \wedge \dots \wedge dx^{n}.
  \end{equation}
  There is a fundamental difference: the polyform indices run over $i$, while the superfield indices $a$ need not be the same as $i$. However, if they have the same indexing set, then these are really similar.
\end{remark}

\section{Differentiation and Integration of Fermions}%
\label{sec:differentiation_and_integration_of_fermions}

\begin{definition}[derivation]
  A \emph{derivation} of a (super-)algebra $A$ is a linear map $D: A \to A$ obeying
  \begin{equation}
    D(ab) = (Da) b + (-1)^{\abs{a} \abs{D}} a (Db) \qquad (\text{graded Leibniz rule}).
  \end{equation}
\end{definition}

\begin{example}[]
  On $\mathbb{R}^{p \mid q}$ , we have even derivatives $\frac{\partial}{\partial x^{i}}$  and odd derivatives $\frac{\partial }{\partial \psi^{a}}$, which act in the way you would expect on single fields:
  \begin{equation}
    \frac{\partial }{\partial x^{i}} (x^{j}) = \delta^{j}_{i} \qquad \frac{\partial }{\partial x^{i}} \psi^{a} = 0 \qquad \frac{\partial x^{j}}{\partial \psi^{a}} = 0 \qquad \frac{\partial }{\partial \psi^{a}} (\psi^{b}) = \delta_{a}^{b}.
  \end{equation}
  However, 
  \begin{equation}
    \frac{\partial }{\partial \psi^{a}} (\psi^{b} \psi^{c}) = \delta^{b}_{a} \psi^{c} - \psi^{b} \delta^{c}_{a}.
  \end{equation}
\end{example}

More generally, a (smooth) vector field on $\mathbb{R}^{p \mid q}$  is 
\begin{equation}
  X(x, \psi) = X^{i}_0 (x, \psi) \frac{\partial }{\partial x^{i}} + X^{a}_1(x, \psi) \frac{\partial }{\partial \psi^{a}}, 
\end{equation}
where $X^{i}_0, x^{a}_1 \in C^\infty(\mathbb{R}^{p \mid q})$.

For integration, since $f(\psi) = \rho + a \psi$, we only need to define $\int 1 \dd[]{\psi}$ and $\int \psi \dd[]{\psi}$.
We require our measure $\dd[]{\psi}$ to be translation invariant\footnote{In particular, this will be necessary to derive Ward identities in QFT.}: if $\psi' = \psi + \eta$ for some fixed fermionic $\eta \in \mathbb{R}^{0 \mid 1}$, then  we want 
\begin{equation}
  \int \psi' \dd[]{\psi'} = \int (\psi + \eta) \dd[]{\psi} = \int \psi \dd[]{\psi} + \eta \int \dd[]{\psi} \implies \boxed{\int 1 \dd[]{\psi} = 0}.
\end{equation}
We then normalise our measure by defining
 \begin{equation}
  \boxed{\int \psi \dd[]{\psi} = 1}
\end{equation}
These rules are called \emph{Berezin integration}.

\begin{leftbar}
  \begin{remark}
    Differentiation and integration is really the same thing. Not unlike complex variables.
  \end{remark}
\end{leftbar}

\begin{remark}
  These imply that
   \begin{equation}
     \int \frac{\partial }{\partial \psi} (F (\psi, \dots)) \dd[]{\psi} = 0.
  \end{equation}
  In other words, when we perform integration by part for fermions, we never have to worry about boundary terms as long as we are careful about minus signs.
\end{remark} 

Suppose that we instead have a general case of $n$  fermionic variables $\psi^{a}$ . Then by iterated application of the previous rules, we define
\begin{equation}
  \int \psi^1 \psi^2 \dots \psi^n \dd[n]{\psi} = 1
\end{equation}
if they all appear, and zero otherwise.
If they all appear, but not in the correct order, then we get extra minus signs
\begin{equation}
  \int \underbrace{\psi^{a} \psi^{b} \dots \psi^{c}}_{\mathclap{n \text{ fermions}}} \dd[n]{\psi} = e^{ab \dots c}.
\end{equation}
\begin{leftbar}
  \begin{remark}
    Note in particular that if any index appears twice, the square on the left-hand side vanishes, just like the Levi-Civita symbol on the right.
  \end{remark}
\end{leftbar}

Suppose $\chi^{a} = N\indices{^{a}_{b}} \psi^{b}$  for some $N \in GL(n , \mathbb{R})$ . Then by linearity
\begin{align}
  \int \chi^{a_1} \dots \chi^{a_n} \dd[n]{\psi} &= N\indices{^{a_1}_{b_1}} \dots N\indices{^{a_n}_{b_n}} \int \psi^{b_1} \dots \psi^{b_n} \dd[n]{\psi} \\
  &= N\indices{^{a_1}_{b_1}} \dots N\indices{^{a_n}_{b_n}} \epsilon^{b_1 b_2 \dots b_n} \\
  &= \det(N) \epsilon^{a_1 \dots a_n} \\
  &= \det(N) \int \chi^{a_1} \chi^{a_2} \dots \chi^{a_n} \dd[n]{\chi}.
\end{align}
We conclude that if $\chi^{a} = N\indices{^{a}_{b}} \psi^{b}$ , then $\dd[n]{\chi} = \frac{1}{\det(N)} \dd[n]{\psi}$ .
\begin{leftbar}
  \begin{remark}
    This is not the same as if you were doing bosonic integration, where you do not have the inverse of the determinant.
  \end{remark}
\end{leftbar}
\begin{example}[]
  If $\chi = a \psi$, then $\dd[]{\psi} = d(a \psi) = \frac{1}{a} \dd[]{\psi}$.
\end{example}

\section{QFT in Zero Dimensions}%
\label{sec:qft_in_zero_dimensions}

\subsection{Bosonic Theory}%
\label{sub:bosonic_theory}

In $d = 0$, our whole universe is just a single point  $M = \left\{ \text{pt} \right\}$ . So a bosonic field is just a map $x \colon M \to \mathbb{R} \simeq \left\{ \text{pt} \right\} \to \mathbb{R}$ , which is nothing else than a real variable.
With $n$ such real fields, the space of all field configurations is $\mathcal{C} = \mathbb{R}^n$ .
The path-integral measure $[\pdd{X}]$  is just the usual Lebesgue measure $\dd[n]{x}$. 
Then the partition function becomes $Z = \int_{\mathbb{R}^n} e^{- {S}(x) / \hbar} \dd[n]{x}$, where $S \colon \mathbb{R}^n \to \mathbb{R}$ is the action.
\begin{leftbar}
  Compare this with today's lecture on \emph{Advanced Quantum Field Theory}.
\end{leftbar}

There cannot be any kinetic terms since the universe is just a point and there cannot be anything we differentiate with respect to.
However, we can have a mass term and maybe some sort of interaction such as
\begin{equation}
  S(x^{i}) = \frac{m_2}{2} \delta_{ij} x^{i} x^{j} + \frac{\lambda^{ijkl}}{4} x^{i} x^{j} x^{k} x^{l}.
\end{equation}
Now in $d = 0$ this is a finite-dimensional integral.
But nonetheless, it is a difficult integral! Expanding the action to quadratic order around its stationary point, we can find that in the limit  $\hbar \to 0^+$, the integral is asymptotic to
 \begin{equation}
   \int_{\mathbb{R}^n} e^{-S(x) / \hbar} \dd[n]{x} \sim (2 \pi \hbar)^{n / 2} \frac{e^{-S(x_*)}}{(\det \partial_{i} \partial_{j} S)^{1 / 2}\rvert_{x = x_*}}
   \left(  1 + \hbar A_1 + \hbar^2 A_2 + \dots \right), \qquad (\text{steepest descent})
\end{equation}
where $x_*$ is a minimum of  $S(x)$ .

This is complicated! And approximate (zero radius of convergence)! 
\begin{remark}
  In the whole of the QFT course we basically just computed different numerators of this.  In AQFT we will go on to loop diagrams and compute the denominator as well as the first order expansion.
  If you end up doing a PhD in the wrong area, you might compute higher and higher terms. But what is even the point? This series doesn't even converge!
\end{remark}

\subsection{Fermionic Theory}%
\label{sub:fermionic_theory}

Let us now consider a purely fermionic theory. We need at least two fermions.
Take $S = A \psi^1 \psi^2$.
\begin{equation}
  Z = \int e^{-S (\psi) / \hbar} \dd[2]{\psi} = \int \left( 1 - \frac{A}{\hbar} \psi^1 \psi^2 \right) \dd[2]{\psi} = - \frac{A}{\hbar}.
\end{equation}
More generally, for $2m$  fermions $\psi^{a}$  and antisymmetric matrix $A_{ab}$ ,
\begin{align}
  Z &= \int e^{-\frac{A_{ab}}{2 \hbar} \psi^a \psi^{b}} \dd[2m]{\psi} = \sum_{k = 0}^{\infty} \frac{(-1)^k}{(2 \hbar)^k k!} \int (A_{ab} \psi^{a} \psi^{b})^k \dd[2m]{\psi}  \\
    &= \frac{(-1)^m}{(2 \hbar)^{m} m!} \epsilon^{a_1 b_1 \dots a_m b_m} A_{a_1 b_1 } \dots A_{a_m b_m} \\
    &= \left( \frac{-1}{\hbar} \right)^m \text{Pfaff}(A).
    \label{eq:2-g}
\end{align}
\begin{definition}[Pfaffian]
  In the preceding derivation, we stumbled across the \emph{Pfaffian} of a $2m \times 2m$ antisymmetric matrix $A$, defined by
  \begin{equation}
    \text{Pfaff}(A) = \frac{1}{2^m m!} e^{a_1 a_2 \dots a_{2m}} A_{a_1 a_2} \cdots A_{a_{2m-1} a_{2m}}.
  \end{equation}
\end{definition}
\begin{exercise}
  For antisymmetric A, show that $(\text{Pfaff } A)^2 = \det A$.
\end{exercise}
This means that the Gaussian integral \eqref{eq:2-g} can be written as $\pm \sqrt{\det A}$.
\begin{leftbar}
  \begin{remark}
    Again, up to a normalisation of the measure, this is the inverse to what you expect from the bosonic counterpart of the Gaussian integral.
  \end{remark}
\end{leftbar}
